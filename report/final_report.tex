\input{config.tex}
\input{shortkey.tex}
\newcommand{\link}[2]{ \href{#1}{\textcolor{Gray}{#2}}}
\newcommand{\statatab}[1]{
\begin{table}[H]\centering\begin{threeparttable}
\input{#1}\end{threeparttable}\end{table}}

\pagestyle{main}
\begin{document}
%\setlength{\parindent}{0cm}
\setlength{\baselineskip}{1.75em}
\setlength{\parskip}{0.5em}

%%%%%% 抬頭 %%%%%%
\thispagestyle{empty}
\begin{center}
{\optima\LARGE Machine Learning Final Project}\\[1em]
電機五~王亮博~B98901114 \\
經研二~顏嘉儀~R01323019 \\
xxx 彭菘瑋 xxxxxxxxx
\end{center}

%%%%% Workflow %%%%%%
\section{整理流程簡介}
基本上我們這組主要專注在 feature 的轉換與選擇，一開始的想法是想透過選出比較有意義的 feature，這樣也許用簡單的 model，例如 linear regression 就可以獲得不錯的準確度。很可惜的是從結果來說我們目前用的幾個方法都並沒有非常顯著的改善。在最後也會提出我們的推論，以及未來可以改進的方向。

\figref{fig:workflow-overview} 所示即為本次整體的處理流程，能分成 Feature Selection 以及 Model Selection 兩大部份。透過 feature selection 之後，我們可以得到不同種方法產生的多個 feature space。之後在 Train model 時，就可以從這些 feature 中選出一部份來 train 我們的 model。

由於我們選用的 feature 可能會牽涉到高維度的轉換， $v_{dc}$ 的增加會讓我們有 overfitting 的問題，所以我們對此有兩個可以解決的方向：
在 model 選擇上，我們會盡量選擇 $v_{dc}$ 較低的演算法，例如 SVM、有 regularization 的 regression。其次為盡量減少最後選用 feature 的數目，可以考慮用 PCA 等方向降維。比較可惜的是，因為時間的關係，我們還沒有做到減少 feature 選用；此外，我們在 feature 轉換中，「Bag-of-Words」的方法尚未實作出，會在下文繼續做相關的說明。

而在 Model Selection 的部份，SVM 類我們使用 cross valdiation 的方式，找出最佳的參數組合；在 Neural Network (NN) 設計我們同樣使用 cross validation 來去判斷如何調整我們 NN 的層數、node 數等。最後，我們比較這些 model 中找出一個在 validation 中表現最好重新以全部的資料 train，並上傳結果。

\insertfigx{workflow/overview}{0.5}{整體處理流程}{fig:workflow-overview}{htb}

\section{Feature Selection}
\subsection*{60x60 Resize}
\subsection*{SIFT Intro}
\subsection*{SIFT Datawise Pair Match}
\subsection*{SIFT BoW Cluster}

\section{Model Selection}
\subsection*{SVM}
\subsection*{Neural Network}

\section{Performance Comparison}

\section{Conclusion}

\end{document}

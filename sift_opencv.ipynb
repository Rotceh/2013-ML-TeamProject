{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Try SIFT and SURF"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "They have been implemented in OpenCV, so first one needs to install OpenCV:\n",
      "\n",
      "- On Mac:  `brew install opencv --with-tbb`\n",
      "- On Ubuntu: I don't know @@\n",
      "\n",
      "OpenCV works only on Python 2.x, so ... you might switch to 2.x in this approach.\n",
      "\n",
      "SIFT and SURF are both algorithms for recognizing scale/rotate invariant features. Basically, after an parser reads an image, it returns a list of feature vectors. \n",
      "\n",
      "$$\n",
      "F_{N, p}\n",
      "= \\begin{bmatrix}\n",
      "    \\mathbf{f}_1 \\\\\n",
      "    \\mathbf{f}_2 \\\\\n",
      "    \\vdots \\\\\n",
      "    \\mathbf{f}_N\n",
      "\\end{bmatrix}\n",
      "= \\begin{bmatrix}\n",
      "      f_{1,1} & f_{1,2} & \\cdots & f_{1,p} \\\\\n",
      "      f_{2,1} & f_{2,2} & \\cdots & f_{2,p} \\\\\n",
      "      \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
      "      f_{N,1} & f_{N,2} & \\cdots & f_{N,p}\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "- $\\mathbf{f}_i = [f_{i, 1} \\ldots f_{i, p}],~\\mathbf{f}_i \\in \\mathbb{R}^{p}$ is a feature vector. In SIFT, usually $p=128$\n",
      "- N is the number of feature vectors, **every image has different number of vectors**\n",
      "\n",
      "By using SIFT or SURF, we can extract a new lists of vectors with new dimension $p$, which are resistance to noise or modification like rotation or shift. But since every image returns a different length of list, we **cannot put them into SVM directly**. We need to select a fixed length of list, say 5 vectors, and treat them as a length of $5 p = 640$ vector into SVM.\n",
      "\n",
      "The procedure is called **Bag-of-Words** (BoW) model. Here we have 12 zodiac signs, which implies all train and test images, their freature vectors could be clustered into 12 different groups. Images of \u9f20 should have features centered in some vector $\\mathbf{cen}_1$, and images of \u725b should have features centered in vector $\\mathbf{cen}_2$, and so on so forth.\n",
      "\n",
      "In the end, we will have 12 vectors represent 12 different center, if our data have good quality, these vectors should be very different! So if a new image comes, we could classify it by seeing its vectors are closed to which center vector $\\mathbf{cen}_i$, then it should belong to that zodiac sign. Then we are classifing by **minimum distance** approach.\n",
      "\n",
      "**Minimum distance** has some problems that we often cannot repesent a list of feature vectors well by using their center only.\n",
      "\n",
      "Further information see reference 2.\n",
      "\n",
      "\n",
      "\u6211\u60f3\u9019\u90e8\u4efd\u61c9\u8a72\u662f\u53ef\u4ee5\u505a\uff0c\u4f46\u771f\u7684\u6709\u9ede\u82b1\u6642\u9593\uff0c\u5982\u679c\u5927\u5bb6\u90fd\u8ddf\u4e0a\u518d\u8003\u616e\u5427\u2026\n",
      "\n",
      "\n",
      "## Reference\n",
      "\n",
      "1. OpenCV, SIFT, ... (C++) <http://blog.csdn.net/xiaowei_cqu/article/category/923660/2>\n",
      "2. <http://stackoverflow.com/questions/17961635/image-detection-features-sift-histogram-and-egde>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "HOG"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similar to SIFT/SURF, but relatively easier and always return a **fixed-length** vector. I guess it is easier to do.\n",
      "\n",
      "## Reference\n",
      "\n",
      "- Using keywords: HOG, SVM\n",
      "- <http://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}